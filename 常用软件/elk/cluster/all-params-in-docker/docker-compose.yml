version: '3.3'


####################  提供部分命令测试集群  #####################
# 查看Elasticsearch节点情况
# curl -u elastic:changeme http://192.168.27.11:9200/_cat/nodes?v
# 查看ES集群健康状态
# curl -u elastic:changeme http://192.168.27.11:9200/_cluster/health?pretty
# 查看集群状态，别人说，下面的命令有显示内容，说明集群搭建成功
# curl -u elastic:changeme http://192.168.27.11:9200/_cat/health?v
# 查看集群信息
# curl -u elastic:changeme 'http://192.168.27.11:9200/_cluster/stats?human&pretty'
# 查看es信息
# curl -u elastic:changeme http://192.168.27.11:9200?pretty
# 查看Elasticsearch索引状态
# curl -u elastic:changeme http://192.168.27.11:9200/_cat/indices?v
# curl -u elastic:changeme 'http://192.168.27.11:9200/_cat/shards?h=index,shard,prirep,state,unassigned.reason&pretty'
# curl -u elastic:changeme 'http://192.168.27.11:9200/_cluster/health?level=indices&pretty'
####################  提供部分命令测试集群  #####################


# docker中的elasticsearch是以elasticsearch用户运行的，docker挂载并创建的目录属于root，elasticsearch用户没有写权限，需要对目录进行授权 
# groupadd elasticsearch
# useradd elasticsearch -g elasticsearch -p elasticsearch
# chown -R elasticsearch.elasticsearch ./data/es-data             # 给es的数据目录授权, 否则es服务启动报错
# chown -R elasticsearch.elasticsearch ./var/log/elasticsearch    # 给es的日志目录授权, 否则es服务启动报错

services:
  elasticsearch01:
    image: elasticsearch:7.7.1
    restart: always
    container_name: elasticsearch01
    privileged: true
    environment:
      - cluster.name=elasticsearch-cluster
      - node.name=node01
      - node.master=true  # 是否是master节点
      - node.data=true    # 是否是数据节点
      - bootstrap.memory_lock=true   # 设置为true锁住内存，当服务混合部署了多个组件及服务时，应开启此操作，允许es占用足够多的内存
      - indices.breaker.request.limit=10%  # 设置单个request请求的内存熔断限制，默认是jvm堆的60%（es7.0引入了新的内存熔断机制，会智能判断，规避OOM）
      - indices.queries.cache.size=20%     # query请求可使用的jvm内存限制，默认是10%
      - indices.requests.cache.size=2%     # 查询request请求的DSL语句缓存，被缓存的DSL语句下次请求时不会被二次解析，可提升检索性能，默认值是1%
      - indices.fielddata.cache.size=30%   # 设置字段缓存的最大值，默认无限制。
      - node.attr.box_type=hot             # 用来对索引数据进行冷热分离，需要注意的是 setting 中也要进行相关配置 "index.routing.allocation.require.box_type": "hot"
      - search.max_buckets=100000000
      - http.cors.enabled=true
      - http.cors.allow-origin=*
      - cluster.initial_master_nodes=node01,node02,node03
      - "ES_JAVA_OPTS=-Xms768m -Xmx768m" # 集群模式，Xms和Xmx要相等，否则抛错 initial heap size [268435456] not equal to maximum heap size [536870912]; this can cause resize pauses and prevents mlockall from locking the entire heap
#     - discovery.zen.ping.unicast.hosts=192.168.27.11,192.168.27.12,192.168.27.13 # ip地址配置方式
      - discovery.zen.ping.unicast.hosts=elasticsearch01,elasticsearch02,elasticsearch03
      - discovery.zen.minimum_master_nodes=2
      - discovery.zen.ping_timeout=120s
      - client.transport.ping_timeout=60s
      - network.publish_host=192.168.27.11
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=changeme
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - /etc/localtime:/etc/localtime
#     - ./data/es/node1:/usr/share/elasticsearch/data
#     - ./logs/es/node1:/usr/share/elasticsearch/logs
#   ports:
#     - 9201:9200
#     - 9301:9300
    networks:
      elk-network:
        ipv4_address: 192.168.27.11


  elasticsearch02:
    image: elasticsearch:7.7.1
    restart: always
    container_name: elasticsearch02
    privileged: true
    environment:
      - cluster.name=elasticsearch-cluster
      - node.name=node02
      - node.master=true  # 是否是master节点
      - node.data=true    # 是否是数据节点
      - bootstrap.memory_lock=true   # 设置为true锁住内存，当服务混合部署了多个组件及服务时，应开启此操作，允许es占用足够多的内存
      - indices.breaker.request.limit=10%  # 设置单个request请求的内存熔断限制，默认是jvm堆的60%（es7.0引入了新的内存熔断机制，会智能判断，规避OOM）
      - indices.queries.cache.size=20%     # query请求可使用的jvm内存限制，默认是10%
      - indices.requests.cache.size=2%     # 查询request请求的DSL语句缓存，被缓存的DSL语句下次请求时不会被二次解析，可提升检索性能，默认值是1%
      - indices.fielddata.cache.size=30%   # 设置字段缓存的最大值，默认无限制。
      - node.attr.box_type=hot             # 用来对索引数据进行冷热分离，需要注意的是 setting 中也要进行相关配置 "index.routing.allocation.require.box_type": "hot"
      - search.max_buckets=100000000
      - http.cors.enabled=true
      - http.cors.allow-origin=*
      - cluster.initial_master_nodes=node01,node02,node03
      - "ES_JAVA_OPTS=-Xms768m -Xmx768m"
      - discovery.zen.ping.unicast.hosts=elasticsearch01,elasticsearch02,elasticsearch03
      #- discovery.zen.ping.unicast.hosts=192.168.27.11,192.168.27.12,192.168.27.13
      - discovery.zen.minimum_master_nodes=2
      - discovery.zen.ping_timeout=120s
      - client.transport.ping_timeout=60s
      # 如果是拆分版，这条配置必须加上，指定当前节点访问的ip
      - network.publish_host=192.168.27.12
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=changeme
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - /etc/localtime:/etc/localtime
#     - ./data/es/node1:/usr/share/elasticsearch/data
#     - ./logs/es/node1:/usr/share/elasticsearch/logs
#   ports:
#     - 9202:9200
#     - 9302:9300
    networks:
      elk-network:
        ipv4_address: 192.168.27.12


  elasticsearch03:
    image: elasticsearch:7.7.1
    restart: always
    container_name: elasticsearch03
    privileged: true
    environment:
      - cluster.name=elasticsearch-cluster
      - node.name=node03
      - node.master=true  # 是否是master节点
      - node.data=true    # 是否是数据节点
      - bootstrap.memory_lock=true   # 设置为true锁住内存，当服务混合部署了多个组件及服务时，应开启此操作，允许es占用足够多的内存
      - indices.breaker.request.limit=10%  # 设置单个request请求的内存熔断限制，默认是jvm堆的60%（es7.0引入了新的内存熔断机制，会智能判断，规避OOM）
      - indices.queries.cache.size=20%     # query请求可使用的jvm内存限制，默认是10%
      - indices.requests.cache.size=2%     # 查询request请求的DSL语句缓存，被缓存的DSL语句下次请求时不会被二次解析，可提升检索性能，默认值是1%
      - indices.fielddata.cache.size=30%   # 设置字段缓存的最大值，默认无限制。
      - node.attr.box_type=hot             # 用来对索引数据进行冷热分离，需要注意的是 setting 中也要进行相关配置 "index.routing.allocation.require.box_type": "hot"
      - search.max_buckets=100000000
      - http.cors.enabled=true
      - http.cors.allow-origin=*
      - cluster.initial_master_nodes=node01,node02,node03
      - "ES_JAVA_OPTS=-Xms768m -Xmx768m"
      - discovery.zen.ping.unicast.hosts=elasticsearch01,elasticsearch02,elasticsearch03
      #- discovery.zen.ping.unicast.hosts=192.168.27.11,192.168.27.12,192.168.27.13
      - discovery.zen.minimum_master_nodes=2
      - discovery.zen.ping_timeout=120s
      - client.transport.ping_timeout=60s
      - network.publish_host=192.168.27.13
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=changeme
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - /etc/localtime:/etc/localtime      
#     - ./data/es/node1:/usr/share/elasticsearch/data
#     - ./logs/es/node1:/usr/share/elasticsearch/logs
#   ports:
#     - 9203:9200
#     - 9303:9300
    networks:
      elk-network:
        ipv4_address: 192.168.27.13


  # kibana:
  #   image: kibana:7.2.0
  #   container_name: kibana
  #   ports:
  #     - 5601:5601
  #   volumes:
  #     - /etc/localtime:/etc/localtime
  #     - ./kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:rw
  #   depends_on:
  #     - elasticsearch_n0
  #   networks:
  #     percona-xtradb-cluster-network:
  #       ipv4_address: 172.16.17.15

networks:
  elk-network:
    driver: bridge
    ipam:
      config:
       - subnet: 192.168.27.0/24

